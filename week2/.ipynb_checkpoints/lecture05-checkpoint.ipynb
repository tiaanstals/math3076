{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 05: Continued fractions continued, and Newton's method ++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last time we looked at continued fractions for irrational numbers like $\\sqrt{2}$, and the golden ratio $(1+\\sqrt{5})/2$. We found that the continued fraction sequences for these numbers are generated by recursion relations of the form\n",
    "\n",
    "$$\\large r_{n+1} = \\frac{r_{n}+1}{r_{n}} \\ = \\ 1 + \\frac{1}{r_{n}}, \\quad \\mathrm{where} \\quad r_{0} \\ = \\ 1. $$\n",
    "\n",
    "\n",
    "This is the sequence that generates the golden ratio in the sense that \n",
    "\n",
    "$$\\large \\lim_{n\\to \\infty} r_{n} \\ = \\ \\phi \\ = \\ \\frac{1+\\sqrt{5}}{2}.$$\n",
    "\n",
    "For finite $n$, we know that each $r_{n}$ is a *rational* number, that means it's the ratio of two integers. Let's see if we can learn something about these integers. Say that \n",
    "\n",
    "$$\\large r_{n} \\ = \\ \\frac{i_{n+1}}{i_{n}},$$\n",
    "\n",
    "were $i_{n}$ are just integers. Plug this into the recursion for $r_{n+1}$ and see what happens. \n",
    "\n",
    "$$\\large r_{n+1} \\ = \\ \\frac{i_{n+2}}{i_{n+1}} \\ = \\ \\frac{\\frac{i_{n+1}}{i_{n}} + 1}{\\frac{i_{n+1}}{i_{n}}} \\ = \\ \\frac{i_{n+1} + i_{n}}{i_{n+1}}$$\n",
    "\n",
    "We can cancel the denominator as long as $i_{n+1} \\ne 0$. Therefore, \n",
    "\n",
    "$$\\large i_{n+2} \\ = \\ i_{n+1} + i_{n}.$$  \n",
    "\n",
    "***This is the famous Fibonacci sequence.*** We also want $i_{0} = i_{1} = 1$, since we want $r_{0} = 1$. \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translating between math and code\n",
    "\n",
    "Before I go any further, I've noticed something in past tutorials. A lot of the newcomers to code were having a hard time putting a mathematical expression into code. I think it's because they thought it needed to be complicated. \n",
    "\n",
    "When you get started, a lot of people tend to show some kind of fear associated with just starting to write code. I know this because I remember being in the same situation. I don't entirely know what the reason is, but it's a pretty universal feeling. \n",
    "\n",
    "But the *great* thing about an interpreted language like Python (using notebooks no less) is that you can make mistakes all day and not hurt anything. \n",
    "\n",
    "So, if I ask to define a function that does XYZ, and you don't know what that means exactly, just start by defining a function. *Any function*. At least any function that you can get working right away. It can be as simple as $f(x) = x^2$, anything to get the ball rolling. Then once you have the `def` and `return` statements in place you can work on filling in the things you don't understand yet. \n",
    "\n",
    "### Example of how can we translate between math and code?\n",
    "\n",
    "Take \n",
    "\n",
    "$$\\large r_{n+1} = \\frac{r_{n}+1}{r_{n}}, \\quad \\mathrm{where} \\quad r_{0} \\ = \\ 1. $$\n",
    "\n",
    "This is somewhat out of order. In code you don't put the initial condition last. You put it at the beginning, that's why it's called \"initial\".\n",
    "\n",
    "\n",
    "$$\\large r_{0} \\ = \\ 1.$$\n",
    "\n",
    "$$\\large r_{n+1} = \\frac{r_{n}+1}{r_{n}}$$\n",
    "\n",
    "Better. \n",
    "\n",
    "Now you need to be careful how you tell a computer to count. If you are not careful you might tell it to count to infinity and it will never get there. We want a rule for giving us $r_{n}$ given the values that we already have, i.e., $r_{n-1}$. So let's make the small shift. \n",
    "\n",
    "$$\\large r_{0} \\ = \\ 1.$$\n",
    "\n",
    "$$\\large r_{n} = \\frac{r_{n-1}+1}{r_{n-1}}$$\n",
    "\n",
    "Even better. \n",
    "\n",
    "But remember that $r_{n}$ is both a number with a subscript $n$, and a discrete function of $n$. Always remember: a function is a black box. You give it something ($n$), and it gives you something back ($r_{n}$). It doesn't matter how we *denote* the function, it is still a function. But programming languages don't traffic in subscripts. They almost all like old fashion function notation; discrete or not. So lets make the change $r_{n} \\to r(n)$. \n",
    "\n",
    "$$\\large r(0) \\ = \\ 1.$$\n",
    "\n",
    "$$\\large r(n) = \\frac{r(n-1)+1}{r(n-1)}$$\n",
    "\n",
    "Looking more `computer` all the time. \n",
    "\n",
    "But now we notice that there are a few things left unsaid about the second equation. It doesn't work when $n=0$. Because then we ask for $r(-1)$, which we don't know and that would ask for $r(-2)$, etc, and it would be off to the races. And we really don't want to have $r(0)$ as a thing. We want $r(n)$ for any legitimate $n$ we might ask for. So \n",
    "\n",
    "$\\large \\textit{if} \\quad  n \\ = \\ 0 : $\n",
    "\n",
    "$$\\large r(n) \\ = \\ 1.$$\n",
    "\n",
    "$\\large \\textit{if} \\quad  n \\ > \\ 0 : $\n",
    "\n",
    "$$\\large r(n) = \\frac{r(n-1)+1}{r(n-1)}$$\n",
    "\n",
    "We can even make one last reformulation to make it so we don't write $r(n-1)$ more than once. \n",
    "\n",
    "\n",
    "$\\large \\textit{if} \\quad  n \\ = \\ 0 : $\n",
    "\n",
    "$$\\large r(n) \\ = \\ 1.$$\n",
    "\n",
    "$\\large \\textit{if} \\quad  n \\ > \\ 0 : $\n",
    "\n",
    "$$\\large r(n) \\ = \\ 1 \\ + \\ \\frac{1}{r(n-1)}$$\n",
    "\n",
    "This all makes the hidden assumption that $n$ is a non-negative integer. You could make this more explicit if you were worried about someone missing the point. \n",
    "\n",
    "Here it is in Python code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r(n): \n",
    "    if n == 0: return 1\n",
    "    return 1 + 1 / r(n-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It takes less Python code to express the function that the math it self!\n",
    "\n",
    "**PS:** This is the style of question you might expect on a final exam. \n",
    "\n",
    "It runs fast! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logic = Logic\n",
    "\n",
    "Kind of cool, notice that it works if the `if` statements are the other way around. So you *can* put the \"initial\" condition last if you are very explicit what the condition actually is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r(n): \n",
    "    if n > 0: return 1 + 1 / r(n-1)\n",
    "    return 1\n",
    "\n",
    "print(r(300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the two functions do behave a little different for bogus input values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r(3.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r(n): \n",
    "    if n > 0: return 1 + 1 / r(n-1)\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might be even *slightly* better because most cases will be `> 0`, and will therefore end sooner in the logic. It doesn't matter at all in this case for speed. But this can make a big difference for other programs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, we got the math into a form that was very easy to translate into code with the following steps\n",
    "\n",
    "    1) Initial conditions come first.\n",
    "    \n",
    "    3) Make sure an index counts in a direction that will stop eventually.\n",
    "    \n",
    "    2) Replace subscripts in favour of function notation, even if everything is discrete.\n",
    "    \n",
    "    3) Replace special cases in functions with conditional statements.\n",
    "    \n",
    "    4) Redo algebra to avoid extra function evaluations. Or use \"memory\" to store data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing what you've seen in the last couple lectures, it would be straightforward to write a recursion formula for the Fibonacci numbers. *You would have to be careful to not to call the recursion too many times at each stage (look at Lecture 04 if you don't recall why). Otherwise it would be slowed down exponentially!*\n",
    "\n",
    "But I want to show a slightly different way to do it. We'll explain more about why this is a good approach as the semester progresses. For now, I want it to be an easy introduction into:\n",
    "\n",
    "## Matrices and Abstraction \n",
    "\n",
    "Consider the matrix,\n",
    "\n",
    "$$\\large F \\ = \\ \\left[\\begin{array}{cc} 1 & 1 \\\\ 1 & 0 \\end{array} \\right]. $$\n",
    "\n",
    "Let's apply $F$ recursively to a 2-dimensional vector. \n",
    "\n",
    "$$\\large \\left[\\begin{array}{c} a_{n+1} \\\\ b_{n+1} \\end{array} \\right] \\ = \\ \\left[\\begin{array}{cc} 1 & 1 \\\\ 1 & 0 \\end{array} \\right] . \\left[\\begin{array}{c} a_{n} \\\\ b_{n} \\end{array} \\right] $$\n",
    "\n",
    "This is the same as \n",
    "\n",
    "$$\\large a_{n+1} = a_{n} + b_{n}, \\quad b_{n+1} =  a_{n} $$\n",
    "\n",
    "We can shift the index of the second equation backwards: $ b_{n} = a_{n-1}$. Altogether this is the same as\n",
    "\n",
    "$$\\large a_{n+1} = a_{n} +  a_{n-1}.$$\n",
    "\n",
    "Another version of the Fibonacci sequence. \n",
    "\n",
    "We can \"solve\" the recursion formally via \n",
    "\n",
    "$$\\large \\left[\\begin{array}{c} a_{n} \\\\ b_{n} \\end{array} \\right] \\ = \\ \\left[\\begin{array}{cc} 1 & 1 \\\\ 1 & 0 \\end{array} \\right]^{n} . \\left[\\begin{array}{c} a_{0} \\\\ b_{0} \\end{array} \\right] $$\n",
    "\n",
    "This uses the matrix power. \n",
    "\n",
    "\n",
    "This illustrates **a very important principle in abstraction**:\n",
    "\n",
    "* A two-term recursion formula for one variable is the same as a one-term recursion for two variables. \n",
    "\n",
    "$$\n",
    "\\large \\text{2-for-1} \\ = \\ \\text{1-for-2}.\n",
    "$$\n",
    "\n",
    "\n",
    "* The same principle applies to more variables. You probably did this in your ODEs class; it also works here too.  \n",
    "    \n",
    "$$\n",
    "\\large n\\text{-for-1} \\ = \\ \\text{1-for-}n.\n",
    "$$\n",
    "\n",
    "\n",
    "* If this recursion formula is linear, then the one-term version can be encoded into a matrix.  \n",
    "    \n",
    "    \n",
    "* If we want, we don't even need to worry about the initial conditions until we are done. \n",
    "\n",
    "\n",
    "* We can do the recursion directly on the matrix itself!\n",
    "\n",
    "Let's program this in Python.\n",
    "\n",
    "I'm going to use the same structure as we saw in Lecture 02 for `fast_exp`. Go back and look at that example if you need to. \n",
    "\n",
    "Also: the version I'm using only works for non-negative values of $n$. You should try to figure out how to make this work with negative values of $n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def matrix_power(F,n):\n",
    "    \"\"\"This uses fast recursion to compute F**n for any square matrix of any data type.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    F (np.array) : square matrix of any size\n",
    "    n (int)      : exponent of F**n\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if type(n) != int: raise ValueError('Only interger exponents allowed.')\n",
    "    \n",
    "    if n < 0: \n",
    "        n *= -1\n",
    "        F = np.linalg.inv(F)\n",
    "    \n",
    "    if n == 0: \n",
    "        return np.identity(len(F),dtype=F.dtype)\n",
    "    elif n%2==0:\n",
    "        M = matrix_power(F,n//2)\n",
    "        return M @ M # @ is matrix multiplication in Python. Can also use M.dot(M)\n",
    "    else:\n",
    "        return F @ matrix_power(F,n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = np.array([[1,1],[1,0]])\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=10\n",
    "print('F**%i ='%n)\n",
    "print(matrix_power(F,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=-10\n",
    "print('F**%i ='%n)\n",
    "print(matrix_power(F,n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice\n",
    "about the entries of the matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = (1+np.sqrt(5))/2\n",
    "\n",
    "def phi_continued_fraction(n):\n",
    "    M = matrix_power(F,n)\n",
    "    return M[0,0]/M[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how well things converge.\n",
    "\n",
    "Make a helper function to help with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_error(A,B): \n",
    "    err = abs(A - B)/B\n",
    "    if err < 2**(-53): return np.inf\n",
    "    return -np.log10(abs(A - B)/B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, 64-bit numbers are only going to be able to cope with 16 digits. The helper checks this and return `inf` for all errors less than this $\\approx 10^{-16}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of iterations versus digits of accuracy:\n",
    "print(\"iteration      digits\")\n",
    "print('---------      ------')\n",
    "for n in range(1,41): \n",
    "    print(\"%2i           %6.1f\" %(n,log_error(phi_continued_fraction(n),phi)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newton's method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In their simplest form, the numbers $\\sqrt{2}$ and $\\large \\phi$ are solutions to simple (quadratic) algebraic equations such as\n",
    "\n",
    "$$\\large  x^{2} - 2 \\ = \\ 0 $$\n",
    "\n",
    "and\n",
    "\n",
    "$$\\large x^{2} - x - 1 \\ = \\ 0$$\n",
    "\n",
    "What do we learn if we try to just solve these equations, and pretend for the moment that we know nothing of continued fractions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Newton's method is perhaps the best place when it comes to root finding. You have probably seen it in 1st year, but it's best to review a little.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Newtons_method\n",
    "\n",
    "\n",
    "Suppose you have a real function of a real variable, $f(x)$. And you want to find a value $x = a$ such that \n",
    "\n",
    "$$\\large f(a) \\ = \\ 0 $$\n",
    "\n",
    "Note: I'm using $a$ as the *specific* value of the solution, and $x$ for any real number that you could plug into the function. \n",
    "\n",
    "### Start with a guess\n",
    "\n",
    "Also suppose you have a reasonable guess $x_{0} \\approx a$ and \n",
    "\n",
    "$$\\large  f(x_{0}) \\approx 0$$.\n",
    "\n",
    "### Make a correction, and solve.\n",
    "\n",
    "We want to find a new guess that does even better. \n",
    "\n",
    "$$\\large f(x_{1}) = f(x_{0} + (x_{1}-x_{0}) ) \\approx f(x_{0}) + f'(x_{0})(x_{1}-x_{0}) \\approx 0 $$. Therefore \n",
    "\n",
    "$$\\large x_{1} = x_{0} - \\frac{f(x_{0})}{f'(x_{0})}$$\n",
    "\n",
    "\n",
    "### Iterate\n",
    "\n",
    "More generally, \n",
    "\n",
    "$$\\large F(x) \\ = \\ x - \\frac{f(x)}{f'(x)} \\ = \\ \\frac{ x\\, f'(x) - f(x) } {f'(x) }  $$\n",
    "\n",
    "We therefore make the iteration\n",
    " \n",
    "$$\\large x_{n+1} \\ = \\ F(x_{n}) $$\n",
    "\n",
    "\n",
    "### $\\large \\sqrt{2}$ example\n",
    "\n",
    "Let's use Newton's method to find $\\sqrt{2}$; a notoriously irrational number: https://en.wikipedia.org/wiki/Square_root_of_2\n",
    "\n",
    "Then\n",
    "\n",
    "$$\\large f(x) = x^2 - 2, \\quad F(x) \\ = \\ \\frac{1}{x} + \\frac{x}{2} \\ = \\ \\frac{x^{2}+2}{2x}$$\n",
    "\n",
    "The result should be the stationary solution. Let's find out if $x = F(x)$ has a solution. This is the same as $2x^{2} = x^2 + 2$. It looks like everything should work in this case.\n",
    "\n",
    "\n",
    "### $\\large \\phi$ example\n",
    "\n",
    "Recall from before\n",
    "\n",
    "$$\\large x_{n+1} \\ = \\ \\frac{x_{n} + 2}{x_{n}+1}$$\n",
    "\n",
    "Alternatively for $\\phi$, \n",
    "\n",
    "$$\\large f(x) = x^2 - x - 1 ,\\quad F(x) \\ = \\  \\frac{x^2+1}{2 x-1}. $$\n",
    "\n",
    "In either case we are (once again) going to iterate,\n",
    "\n",
    "$$\\large x_{n+1} = F(x_{n}).$$\n",
    "\n",
    "\n",
    "\n",
    "Let's do the Newton iteration for $\\phi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_Newton(n):\n",
    "    if n==0: return 1\n",
    "    x = phi_Newton(n-1)\n",
    "    return (x*x+1)/(2*x-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of iterations versus digits of accuracy:\n",
    "print(\"iteration   cf. digits      newton digits \")\n",
    "print('---------   ----------      ------------- ')\n",
    "alert = False\n",
    "for n in range(1,41): \n",
    "    d1 = log_error(phi_continued_fraction(n),phi)\n",
    "    d2 = log_error(phi_Newton(n),phi)\n",
    "    print(\"%2i        %6.1f          %6.1f\" %(n,d1,d2))\n",
    "    if (d1 == np.inf or d2 == np.inf) and not alert: \n",
    "        alert = True\n",
    "        print('----------------------------------- Newton out!')\n",
    "print('----------------------------------- continued fraction out!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**The Newton method is converging *a lot* faster than the continued fraction!** \n",
    "\n",
    "I thought I said continued fractions are the \"fastest converging\" way to represent irrational numbers. Was I wrong?\n",
    "\n",
    "But actually, check out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"i   2**i   phi_Newton(i)         phi_continued_fraction(2**i)\")\n",
    "print(\"--------   -----------------     ----------------------------\")\n",
    "for i in range(1,7):\n",
    "    print(\"%i   %2i     %.15f     %.15f\" %(i,2**i, phi_Newton(i),phi_continued_fraction(2**i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Subsequence \n",
    "\n",
    "It is true that. Continued fractions are still the best *and* Newton is better. That's because Newton iteration is a *subsequence of the continued-fractions sequence*. It skips steps.\n",
    "\n",
    "This is a big ***acceleration***. In this case, it looks like Newton's method is finding the powers of 2 in the continued fraction sequence. Can we prove this? We are *conjecturing* that \n",
    "\n",
    "$$\n",
    "\\large \\text{phi_Newton(i)} \\ = \\text{phi_continued_fraction(2**i)}\n",
    "$$\n",
    "\n",
    "I'll leave it as an exercise to prove this. The same is true for the $\\sqrt{2}$ case.\n",
    "\n",
    "If we were able to find a sequence that skipped big steps in the continued fraction sequence, is it possible to skip even bigger steps?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Halley's method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of Newton's method is to solve equations of the form\n",
    "\n",
    "$$\\large f(x) \\ = \\ 0.$$\n",
    "\n",
    "Not long after Newton, Sir Edmond Halley (of the Comet fame) realised a simple fact. If $h(x) \\ne 0$. Or at least not at the same place as $f(x)$, then solving the modified equation\n",
    "\n",
    "$$\n",
    "\\large \\hat{f}(x) \\ \\equiv  \\ \\frac{f(x)}{h(x)} \\ = \\ 0\n",
    "$$\n",
    "gives the same result as solving $f(x)=0$. But maybe we can find an $h(x)$ that make Newton's for $\\hat{f}(x)$ go faster?  Sir Edmond discovered that \n",
    "\n",
    "$$\\large h(x) \\ = \\ \\sqrt{ | f'(x) |}$$\n",
    "\n",
    "works for this purpose. It works as long as $f(x)$ is twice differentiable and doesn't share any roots with $f'(x)$. After going the calculus for Newton's method, but only for $\\hat{f}(x)$, we find that we need to iterate\n",
    "\n",
    "$$\n",
    "\\large\n",
    "F(x) \\ = \\ x + \\frac{2 f(x) f'(x)}{f(x)\n",
    "   f''(x)-2 f'(x)^2}\n",
    "$$\n",
    "\n",
    "In the case of the golden ratio\n",
    "\n",
    "$$\n",
    "\\large\n",
    "F(x) \\ = \\ \\frac{x^3+3 x-1}{3 x^2-3 x+2}\n",
    "$$\n",
    "\n",
    "Let's try it in Python. This will use more examples of `functional` programming. See if you can follow the flow of logic and compare it to the mathematical formulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 methods in 1\n",
    "\n",
    "Now that we have three different ways of doing the same thing, it's probably worth thinking about how to get organised about it. \n",
    "\n",
    "The only difference between the Continued Fraction, Newton, and Halley methods is the function you iterate. \n",
    "\n",
    "We'll talk about the syntax more carefully soon. But for now, let's store the different methods in a dictionary of `lambda` functions. \n",
    "\n",
    "## $\\large \\lambda$ functions\n",
    "\n",
    "`lambda` functions are *anonymous functions*. They don't need a name to define, and they don't have any internal state. They are black boxes. You can only get out something that's a function of what you put in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = {1: lambda x: 1+1/x , 2: lambda x: (x*x+1)/(2*x-1) ,3: lambda x: (x**3+3*x-1)/(3*x*x-3*x+2)}\n",
    "\n",
    "def phi(n,method):\n",
    "    if n==0: return 1\n",
    "    x = phi(n-1,method)\n",
    "    return F[method](x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They all give the same answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(phi(100,1))\n",
    "print(phi(100,2))\n",
    "print(phi(100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = (1+np.sqrt(5))/2\n",
    "# Number of iterations versus digits of accuracy:\n",
    "print(\"iteration   cf. digits      newton digits      halley digits \")\n",
    "print('---------   ----------      -------------      ------------- ')\n",
    "alert = False\n",
    "for n in range(1,8): \n",
    "    d1 = log_error(phi(n,1),answer)\n",
    "    d2 = log_error(phi(n,2),answer)\n",
    "    d3 = log_error(phi(n,3),answer)\n",
    "    print(\"%2i        %6.1f          %6.1f             %6.1f\" %(n,d1,d2,d3))\n",
    "    if (d2 == np.inf or d3 == np.inf) and not alert: \n",
    "        alert = True\n",
    "        print('---------------------------------------------------------- Halley out!')\n",
    "print('---------------------------------------------------------- Newton out!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faster acceleration \n",
    "\n",
    "It's difficult to show it with \"only\" 16 digits. But what we have is \n",
    "\n",
    "$$\n",
    "\\large \\text{phi_Halley(n)} \\ = \\text{phi_continued_fraction(3**n)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\large \\text{phi_Newton(n)} \\ = \\text{phi_continued_fraction(2**n)}\n",
    "$$\n",
    "\n",
    "Later we'll see that this is actually the case when we work with exact calculations.\n",
    "\n",
    "### Householder beyond Halley\n",
    "\n",
    "Newton's method is the most practically useful aspect of this lecture. \n",
    "\n",
    "* The golden ratio and continued fraction sequences are to give you more ideas about the fundamental structure of irrational numbers. \n",
    "    \n",
    "    \n",
    "* Halley's method is not widely used in serious applications. Newton and even simpler methods are still the best for most cases. \n",
    "    \n",
    "    \n",
    "* The point of showing Halley's method is to highlight the idea of acceleration. It might not surprise you that there are even faster methods. \n",
    "    \n",
    "You can look up **Householder's methods** if you want more info: \n",
    "\n",
    "https://en.wikipedia.org/wiki/Householder's_method\n",
    "\n",
    "Newton and Halley are the first two in the sequence of Householder methods. The $k$th method in Householder's formula skips powers of $k$ in the continued fraction sequence.\n",
    "\n",
    "$$\n",
    "\\large \\text{Householder(k)(n)} \\ = \\text{Continued_Fraction(k**n)}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "### Moral of the story:\n",
    "\n",
    "<h3><center> Using math, it's sometimes possible to accelerate an algorithm by many orders of magnitude. </center></h3>\n",
    "\n",
    "The point here is not that you should use Halley versus Newton. It's that there are gains to be had in an algorithm if you think carefully about it. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algebraic vs Transcendental numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same for $\\pi$ if we want. In this case \n",
    "\n",
    "Solve \n",
    "\n",
    "$$\\large f(x) = \\sin(x) \\ = \\ 0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pi(n):\n",
    "    if n == 0: return 3\n",
    "    x = Pi(n-1)\n",
    "    return x - (2*np.sin(2*x))/(3 + np.cos(2*x))\n",
    "\n",
    "Pi(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or for $e$; \n",
    "\n",
    "Solve \n",
    "$$\\large f(x) = \\log(x) - 1 \\ = \\ 0.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E(n):\n",
    "    if n == 0: return 3\n",
    "    x = E(n-1)\n",
    "    return x*(4/(1 + np.log(x)) - 1)\n",
    "\n",
    "E(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The practical difference: polynomials vs infinite series.\n",
    "\n",
    "There is a big practical difference between $ \\sqrt{2}$ and $ \\phi$ examples, and the $ \\pi$ and $e$ examples.\n",
    "\n",
    "* In the $\\phi$ and $\\sqrt{2}$ examples, either the Continued fraction, Newton, or Halley only requires the evaluation of *polynomials* and their ratios.\n",
    "\n",
    "\n",
    "* In principle, these were all calculations that could be done \"by hand\". I didn't need to resort of `numpy` for anything.\n",
    "\n",
    "\n",
    "* In the $\\pi$ and $e$ examples, you notice that I use `np.sin` and `np.log`. This is because these functions are complicated in ways that I don't want to deal with right now.\n",
    "\n",
    "$$\n",
    "\\large \\sin(x) \\ = \\ \\sum_{k=0}^{\\boldsymbol{\\infty}} (-1)^{k} \\frac{x^{2k+1}}{(2k+1)!}\n",
    "\\quad \\quad \\quad \\cos(x) \\ = \\ \\sum_{k=0}^{\\boldsymbol{\\infty}} (-1)^{k} \\frac{x^{2k}}{(2k)!}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "$$\n",
    "\\large \\log(x) \\ = \\ -\\sum_{k=1}^{\\boldsymbol{\\infty}} \\frac{(1-x)^{k}}{k}\n",
    "$$\n",
    "\n",
    "<h2> <center> Simply computing these function \"requires\" an infinite number of terms! </center> </h2>\n",
    "\n",
    "I put \"requires\" in quotes because of course, *we can never get to $\\infty$!* But it means we have to think about a double limit just to compute $\\pi$ and $e$. \n",
    "\n",
    "\n",
    "* For $ \\sqrt{2}$ and $ \\phi$, we only need a limit in the number of recursion iterations. \n",
    "\n",
    "\n",
    "* For $ \\pi$ and $e$, we need a limit in the number of recursion iterations, *and* the number of terms in the series approximation of the internal functions $\\sin$, $\\cos$ and $\\log$. \n",
    "\n",
    "\n",
    "Therefore...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some working definitions of some numbers\n",
    "\n",
    "\n",
    "**Integer numbers:** Numbers that require no computation to define. \n",
    "\n",
    "\n",
    "\n",
    "**Rational numbers:** Numbers that you can compute in a finite number of operations. \n",
    "\n",
    "\n",
    "**Algebraic numbers:** The iterative solution to finite polynomials equations. \n",
    "\n",
    "\n",
    "**Transcendental numbers:** The iterative solution to equations where *evaluating the equation once* requires  iteration. \n",
    "\n",
    "You can see that there should be an infinite list of kinds of numbers that are progressively harder to compute. At some point you get to numbers that are so hard to compute that we will never actually see them. There are *way* more numbers of this kind than numbers we can get to.\n",
    "\n",
    "All of the above are examples of ***Computable numbers***. These are the only numbers anyone has ever seen or thought about. They are actually only countable infinite, just like the integers. True irrational numbers that are uncomputable have never been seen or used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factorial \n",
    "\n",
    "Notice that the $\\sin$ and $\\cos$ functions even have a recursive function inside them! \n",
    "\n",
    "I haven't mentioned it yet. But this is usually the first example of a recursive function people talk about. \n",
    "\n",
    "$$\n",
    "\\large n! \\ = \\ n \\,\\times\\, (n-1)! \\quad \\quad  \\text{and} \\quad  \\quad 0! \\ = \\ 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial(n): \n",
    "    if n > 0: return n*factorial(n-1)\n",
    "    return 1\n",
    "\n",
    "factorial(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rationals = Integers\n",
    "\n",
    "### So maybe I was a little wrong in my above definitions. \n",
    "\n",
    "It seem that defining factorial integers requires a little calculation. And rational numbers require a little computation. \n",
    "\n",
    "In fact \n",
    "\n",
    "<h3> <center> It's possible to put rational number ans integers into 1-to-1 correspondence. </center> </h3>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/8/85/Diagonal_argument.svg\" width=\"400\" height=\"500\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better definitions:\n",
    "\n",
    "<br>\n",
    "\n",
    "## Rational & Integer numbers:\n",
    "\n",
    "$\\quad \\large \\text{Numbers that you can compute in a finite number of operations.}$\n",
    "\n",
    "<br>\n",
    "\n",
    "## Algebraic numbers:\n",
    "\n",
    "$\\quad \\large \\text{The iterative solution to finite polynomials equations.}$\n",
    "\n",
    "<br>\n",
    "\n",
    "## Transcendental numbers:\n",
    "\n",
    "$\\quad \\large \\text{The iterative solution to equations where evaluating the equation once requires iteration}$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### But math is really slippery sometimes. \n",
    "\n",
    "\n",
    "We can define transcendental numbers $e$ and $\\pi$ *directly*.\n",
    "\n",
    "\n",
    "$$\n",
    "\\large e  \\ = \\ \\lim_{n\\to \\infty}\\ \\left(1+\\frac{1}{n}\\right)^{n}\n",
    "$$\n",
    "\n",
    "### The Wallis product:\n",
    "\n",
    "There is a lot of fun things one could say about this formula \n",
    "\n",
    "$$\n",
    "\\large \\pi  \\ = \\ \\lim_{n\\to \\infty}\\ \\frac{2^{4 n+1} (n!)^4}{(2 n)! (2 n+1)!}.\n",
    "$$\n",
    "\n",
    "https://en.wikipedia.org/wiki/Wallis_product\n",
    "\n",
    "\n",
    "### Convergence is slow\n",
    "\n",
    "Unlike the Newton methods earlier, these recursive functions are *slow* to converge. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Wallis_pi(n):\n",
    "    if n == 0: return 2\n",
    "    return  Wallis_pi(n-1) / (1 - 1/(2*n)**2)\n",
    "\n",
    "print(\" Numpy.pi       : %.16f\" % np.pi)\n",
    "print(\"Wallis_pi(2000) : %.16f\" % Wallis_pi(2000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The error only decreases like $1/n$. The formula for $e$ would be about the same. \n",
    "\n",
    "### But math is double slippery sometimes. \n",
    "\n",
    "Because we also know that \n",
    "\n",
    "$$\n",
    "\\large e  \\ = \\ \\sum_{k=0}^{\\infty} \\frac{1}{k!}\n",
    "$$\n",
    "\n",
    "This is much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_sum(n):\n",
    "    E = 0\n",
    "    for k in range(n+1):\n",
    "        E += 1/factorial(k)\n",
    "    \n",
    "    return E\n",
    "\n",
    "e_sum(20) \n",
    "print(np.e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bottom line:\n",
    "\n",
    "<h3><center> Mathematical reformulation can speed up or slow down algorithms with different degrees of difficulty. </center></h3>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
